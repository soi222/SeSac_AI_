{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfLea9xSQGk6HRXm8xG5wG"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Tensor란?\n",
        "다차원의 배열을 뜻하는 말.<br>\n",
        "배열의 차원에 따라 부르는 이름이 달라지는데요<br>\n",
        "0차원은 스칼라(숫자하나), 1차원은 벡터(열), 2차원은 메트릭스, 그 이상의 다차원은 아래 차원의 것을 모아놓은 배열인 것이라 할 수 있는데요!<br>\n",
        "tensor는 스칼라, 벡터, 매트릭스 등의 데이터와 그 이상의 고차원데이터도 포함하는 개념입니다.<br>참고로 tensor에서 Rank는 그 데이터가 몇 차원의 배열인지를 의미합니다"
      ],
      "metadata": {
        "id": "aX18mcFu70qp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5dENzRwS7v14"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "numpy와 같은 다른 라이브러리도 tensor를 다룰 수 있는데 굳이 파이토치를 사용하는 이유는?<br>바로 파이토치에서는 gradient를 사용할 수 있기 때문입니다."
      ],
      "metadata": {
        "id": "n2PQBWMI9J8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(1., requires_grad = True) #trequires_grad = True : 미분계수를 계산할 수 있는 텐서 생성\n",
        "w = torch.tensor(2., requires_grad = True)\n",
        "b = torch.tensor(3., requires_grad = True)\n",
        "\n",
        "# Bulid a computational graph, 계산 그래프를 작성합니다\n",
        "y = w * x + b\n",
        "\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfYH1uiu8eeu",
        "outputId": "a7d59fd5-ad0b-43ff-fc37-92ff1a068bc2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(5., grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch사용하기\n",
        "\n"
      ],
      "metadata": {
        "id": "SVHA1t_U_NM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(1., requires_grad = True) #trequires_grad = True : 미분계수를 계산할 수 있는 텐서 생성\n",
        "w = torch.tensor(2., requires_grad = True)\n",
        "b = torch.tensor(3., requires_grad = True)\n",
        "\n",
        "# Bulid a computational graph, 계산 그래프를 작성합니다\n",
        "y = w * x + b\n",
        "\n",
        "#gradient 계산 : backpropagation\n",
        "y.backward()\n",
        "\n",
        "#print out the gradients\n",
        "print(x.grad) #tensor(2.) : x가 조금 변하면 결과값은 2배 변한다는 의미\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PlYAFta-naW",
        "outputId": "00ad16c1-f849-4031-b596-4ec3894b03a9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(5., grad_fn=<AddBackward0>)\n",
            "tensor(2.)\n",
            "tensor(1.)\n",
            "tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Deep Learning 모델 학습 과정\n",
        "1. 데이터 불러오기\n",
        "2. Deep model만들기\n",
        "3. loss, otimizer 만들기\n",
        "4. 모델 통과 & loss 계산\n",
        "5. 모델 개선\n",
        "6. 학습된 모델 성능 평가하기\n",
        "```\n",
        "<br>\n",
        "<br>\n",
        "loss 함수(손실 함수) = 실제값과 예측값의 차이를 수치화 해주는 함수로<br> loss 함수를 최소화하는 weight와 bias를 찾도록 딥러닝 모델의 학습방향을 제시해주는 지표<br><br>optimizer = loss합수의 최솟값을 찾는 최적화 알고리즘,<br> loss함수를 최소화 하기 위해 parameters 업데이트를 위한 알고리즘!\n",
        "<br>\n",
        "\n"
      ],
      "metadata": {
        "id": "St5Mt76b_lDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## numpy를 이용한 데이터셋 만들기\n",
        "## torch는 numpy.array를 받을 수 없\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# step1. Create of shape\n",
        "x = np.array([[1,2],[3,4]])\n",
        "y = torch.from_numpy(x)\n",
        "\n",
        "# Convert the numpy to a torch tensor. numpy 배열을 torch 텐서로 변환\n",
        "y = torch.from_numpy(x)\n",
        "\n",
        "# Convert the numpy to a torch numpy array. torch 텐서를 numpy array로 변환\n",
        "z = y.numpy()"
      ],
      "metadata": {
        "id": "J1b4bIarBVG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# step1. Create of shape\n",
        "x = torch.randn(10,3)\n",
        "y = torch.randn(10,2)"
      ],
      "metadata": {
        "id": "-EzgPopT-zhX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step2. Build a fully connected layer. deep model 만들기\n",
        "import torch.nn as nn\n",
        "\n",
        "linear = nn.Linear(3,2)\n",
        "print(\"w:\", linear.weight)\n",
        "print(\"b:\", linear.bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Pg9DR3qCEXN",
        "outputId": "955cc74a-fd0b-4e5b-997a-c5c14adb8100"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w: Parameter containing:\n",
            "tensor([[-0.2541, -0.3975, -0.0535],\n",
            "        [ 0.1993, -0.0624,  0.4918]], requires_grad=True)\n",
            "b: Parameter containing:\n",
            "tensor([0.4375, 0.3279], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#step3. Build loss function and optimizer.\n",
        "criterion = nn.MSELoss()  #nn.MSELoss : 제곱 평균 손실함수\n",
        "optimizer = torch.optim.SGD(linear.parameters(), lr = 0.01) #lr : 보폭"
      ],
      "metadata": {
        "id": "rJKaLsfaCcPJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step4. Forward pass. 모델 통과, loss 계산하기\n",
        "pred = linear(x)\n",
        "\n",
        "# compute loss. loss 계산\n",
        "loss = criterion(pred, y)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkZuBcKBDHxK",
        "outputId": "ac1f787b-458d-4e1d-c9cd-f80200c53024"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.9338, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step5. Backward pass. 모델 계산하기\n",
        "#gradient 초기화\n",
        "loss.backward()\n",
        "\n",
        "print(\"dL/dw:\", linear.weight.grad)\n",
        "print(\"dL/dw:\", linear.bias.grad)\n",
        "\n",
        "#1-step gradiend descent, gradient 변화적용\n",
        "optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_IKGmh5DYBQ",
        "outputId": "26cf8dab-c068-4fe7-d596-c2f28b9be533"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dL/dw: tensor([[-1.4917, -0.7240, -1.1677],\n",
            "        [ 0.8445,  0.3729,  1.0493]])\n",
            "dL/dw: tensor([0.3418, 1.9641])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## step6. Print out the loss after 1-step gradient descent. 1-step gradient descent 이후에 loss를 출력\n",
        "pred = linear(x)\n",
        "loss = criterion(pred,y)\n",
        "print(\"loss after 1-step optimization : \", loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wW-U6JMJD92r",
        "outputId": "26d0294a-4715-4ef3-e3e0-fdbaf16597cb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss after 1-step optimization :  1.8593733310699463\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "step5 ~ 6을 반복하게 된다면 loss값이 줄어드는 것을 확인할 수 있습니다!"
      ],
      "metadata": {
        "id": "Z3v2MHNrFJxE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K-UsXn2gFA0g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}