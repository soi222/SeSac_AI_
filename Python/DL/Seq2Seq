{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM3xs34dmU0yE63fquIWsgj"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbQekzKZgzif"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## clone과 =의 차이\n",
        "\"\"\"\n",
        "a = [1,2,3]\n",
        "\n",
        "b = a\n",
        "b # [1,2,3]\n",
        "\n",
        "b[1] = 3\n",
        "b #[1,3,3]\n",
        "\n",
        "#clone\n",
        "b = a.copy()\n",
        "b[1] = 3\n",
        "b #[1,3,3]\n",
        "a #[1,2,3]\n",
        "\"\"\"\n",
        "\n",
        "#copy()와 clone()의 차이\n",
        "\"\"\"\n",
        "torch 내에서는 copy가 잘 안됨\n",
        "tensor\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "etXnArXoiixV",
        "outputId": "ef03a599-8459-4eec-821f-e7d3d29f0898"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntorch 내에서는 copy가 잘 안됨\\ntensor\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.randn(3,6)\n",
        "print(t)\n",
        "\n",
        "print(t>0)\n",
        "print(torch.sum(t > 0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-LO4nSuZLLJ",
        "outputId": "99dfd7ea-11ff-48ce-bf4f-008e8eae8a77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.8834,  0.8210,  0.3486, -0.8003, -1.7012, -0.6478],\n",
            "        [ 0.4180, -0.5836, -0.0666,  0.5678,  1.5168, -0.4679],\n",
            "        [ 0.2440,  0.4077,  1.4837, -1.0852, -1.5082,  1.0749]])\n",
            "tensor([[ True,  True,  True, False, False, False],\n",
            "        [ True, False, False,  True,  True, False],\n",
            "        [ True,  True,  True, False, False,  True]])\n",
            "tensor(10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional\n",
        "## 데이터 생성 : 시계열로 들어오는 input 모두 사용 가능\n",
        "def generate_dataset(seq_length, num_sample, vocab_size): #vocab_size : 집합의 size\n",
        "  inputs = torch.randint(1, vocab_size, (num_sample, seq_length))\n",
        "  outputs = inputs.clone()\n",
        "\n",
        "  return TensorDataset(inputs, outputs)\n",
        "\n",
        "#generate_dataset(10, 100, 5)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.linear = nn.Linear(input_size, hidden_size)\n",
        "    self.activation = nn.Tanh()\n",
        "\n",
        "  def forward(self,input_seq):\n",
        "    batch_size, seq_length = input_seq.size() #batch_size, seq_length\n",
        "    hidden = torch.zeros(batch_size, self.hidden_size).to(device)\n",
        "\n",
        "    for char_idx in range(seq_length):\n",
        "      x_t = nn.functional.one_hot(input_seq[:,char_idx], num_classes = self.linear.in_features).float()\n",
        "      hidden = self.activation(self.linear(x_t) + hidden)\n",
        "\n",
        "    return hidden\n",
        "\n",
        "\"\"\"\n",
        ".stack()\n",
        ".one_hot()\n",
        "nn.functional\n",
        ".activation\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self,input_size, hidden_size, output_size):\n",
        "    super(Decoder,self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.input_size = input_size\n",
        "    self.output_size = output_size\n",
        "\n",
        "    #self.i2h = nn.Linear(input_size, output_size)\n",
        "    self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "    self.activation = nn.Tanh()\n",
        "    self.linear2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, target_seq, hidden):\n",
        "    batch_size, seq_length = target_seq.size()\n",
        "    outputs = torch.zeros(batch_size, seq_length, self.output_size).to(device)\n",
        "\n",
        "    for char_idx in range(seq_length):\n",
        "      if char_idx == 0:\n",
        "        #이전 input\n",
        "        previous_y = torch.zeros(batch_size, self.input_size).to(device)\n",
        "      else:\n",
        "        y_prev = target_seq[:, char_idx - 1]\n",
        "        # y_minus_1 = nn.functional.one_hot(y_prev, num_classes = self.liner1.in_features).float()\n",
        "        previous_y = nn.functional.one_hot(y_prev, self.input_size).float().to(device)\n",
        "\n",
        "      hidden = self.activation(self.linear1(previous_y) + hidden)\n",
        "      output = self.linear2(hidden)\n",
        "      outputs[:, char_idx, :] = output\n",
        "\n",
        "    return outputs\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, encoder, decoder):\n",
        "    super(Seq2Seq, self).__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def forward(self, input_seq, target_seq):\n",
        "    encoder_hidden = self.encoder(input_seq)\n",
        "    decoder_output = self.decoder(target_seq, encoder_hidden)\n",
        "\n",
        "    return decoder_output\n",
        "\n",
        "def train_model(model, detaloader, criterion, optimizer, num_epochs, device):\n",
        "  model.to(device)\n",
        "\n",
        "  for epoch in range(1, num_epochs + 1):\n",
        "   #train모드로 변경\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for inputs, targets in detaloader:\n",
        "      # input.shape - batch_size, seq_length\n",
        "      inputs,targets = inputs.to(device), targets.to(device)\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      outputs = model(inputs, targets)\n",
        "      outputs = outputs.view(-1, outputs.size(-1)) #batch_size + seq_length, output_size\n",
        "      targets = targets.view(-1)\n",
        "\n",
        "      loss = criterion(outputs, targets)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "      avg_loss = epoch_loss / len(dataloader)\n",
        "    print(f\"Epoch {epoch}, loss {avg_loss}\")\n",
        "\n",
        "def evaluate_model(model, dataloader, device):\n",
        "  model.eval()\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, targets in dataloader:\n",
        "      inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "      outputs = model(inputs, targets) #output : model을 통과 후 계산된 값, batch_size, seq_length, vocab_size\n",
        "\n",
        "      predicted = torch.argmax(outputs, dim = 2)\n",
        "      correct += (predicted == targets).sum().item()\n",
        "      total += targets.size(0) * targets.size(1) #targets.size[0] : batch_size\n",
        "\n",
        "  acc = correct / total\n",
        "  return acc\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "      seq_length = 10\n",
        "      num_samples = 1000\n",
        "      vocab_size = 50  # Including a padding index if needed\n",
        "      hidden_size = 64\n",
        "      batch_size = 32\n",
        "      num_epochs = 20\n",
        "      learning_rate = 0.001\n",
        "\n",
        "      #Device configuration\n",
        "      device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "      #print(f'Using device :{device}')\n",
        "\n",
        "      dataset = generate_dataset(seq_length, num_samples, vocab_size)\n",
        "\n",
        "      # for x, y in dataset:\n",
        "      #   print(x[0], y[0])\n",
        "      #   break\n",
        "      # #input 시퀀스가 있다면 input과 같은 output을 내뱉는 시퀀스 생성\n",
        "      dataloader = DataLoader(dataset, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "      encoder = Encoder(input_size=vocab_size, hidden_size=hidden_size)\n",
        "      decoder = Decoder(input_size=vocab_size, hidden_size=hidden_size, output_size=vocab_size)\n",
        "\n",
        "      model = Seq2Seq(encoder, decoder).to(device)\n",
        "\n",
        "      criterion = nn.CrossEntropyLoss()\n",
        "      optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "      train_model(model, dataloader, criterion, optimizer, num_epochs, device)\n",
        "\n",
        "      acc = evaluate_model(model, dataloader, device)\n",
        "      print(f\"Training Accuracy : {acc * 100:.2f}%\\n\")\n",
        "\n",
        "      with torch.no_grad():\n",
        "        test_input, test_target = dataset[0]\n",
        "        test_input = test_input.unsqueeze(0).to(device)\n",
        "        test_target = test_target.unsqueeze(0).to(device)\n",
        "\n",
        "        output = model(test_input, test_target)\n",
        "\n",
        "        predicted = torch.argmax(output, dim = 2)\n",
        "        print(\"Sample Input Sequence:   \", test_input.squeeze().tolist())\n",
        "        print(\"Sample Target Sequence:  \", test_target.squeeze().tolist())\n",
        "        print(\"Predicted Sequence       :  \", predicted.squeeze().tolist())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csqmpCC9hEjx",
        "outputId": "cce7de6d-7f8c-4b0b-81a9-007bf8edd622"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, loss 3.907924547791481\n",
            "Epoch 2, loss 3.850886218249798\n",
            "Epoch 3, loss 3.791297972202301\n",
            "Epoch 4, loss 3.714547649025917\n",
            "Epoch 5, loss 3.6332777589559555\n",
            "Epoch 6, loss 3.5516472533345222\n",
            "Epoch 7, loss 3.476061962544918\n",
            "Epoch 8, loss 3.4052771627902985\n",
            "Epoch 9, loss 3.336866110563278\n",
            "Epoch 10, loss 3.27262943983078\n",
            "Epoch 11, loss 3.212026685476303\n",
            "Epoch 12, loss 3.153146266937256\n",
            "Epoch 13, loss 3.101070173084736\n",
            "Epoch 14, loss 3.0522862523794174\n",
            "Epoch 15, loss 3.006496213376522\n",
            "Epoch 16, loss 2.962827652692795\n",
            "Epoch 17, loss 2.9240519627928734\n",
            "Epoch 18, loss 2.885907806456089\n",
            "Epoch 19, loss 2.8522115126252174\n",
            "Epoch 20, loss 2.8208874613046646\n",
            "Training Accuracy : 25.80%\n",
            "\n",
            "Sample Input Sequence:    [28, 25, 30, 29, 12, 33, 37, 7, 33, 11]\n",
            "Sample Target Sequence:   [28, 25, 30, 29, 12, 33, 37, 7, 33, 11]\n",
            "Predicted Sequence       :   [33, 33, 33, 33, 33, 33, 33, 33, 33, 11]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Encoder / Decoder 바꾸기\n",
        "import torch.nn.functional\n",
        "## 데이터 생성 : 시계열로 들어오는 input 모두 사용 가능\n",
        "def generate_dataset(seq_length, num_sample, vocab_size): #vocab_size : 집합의 size\n",
        "  inputs = torch.randint(1, vocab_size, (num_sample, seq_length))\n",
        "  outputs = inputs.clone()\n",
        "\n",
        "  return TensorDataset(inputs, outputs)\n",
        "\n",
        "#generate_dataset(10, 100, 5)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.linear = nn.Linear(input_size, hidden_size)\n",
        "    self.activation = nn.Tanh()\n",
        "\n",
        "  def forward(self,input_seq):\n",
        "    batch_size, seq_length = input_seq.size() #batch_size, seq_length\n",
        "    hidden = torch.zeros(batch_size, self.hidden_size).to(device)\n",
        "\n",
        "    for char_idx in range(seq_length):\n",
        "      x_t = nn.functional.one_hot(input_seq[:,char_idx], num_classes = self.linear.in_features).float()\n",
        "      hidden = self.activation(self.linear(x_t) + hidden)\n",
        "\n",
        "    return hidden\n",
        "\n",
        "\"\"\"\n",
        ".stack()\n",
        ".one_hot()\n",
        "nn.functional\n",
        ".activation\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self,input_size, hidden_size, output_size):\n",
        "    super(Decoder,self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.input_size = input_size\n",
        "    self.output_size = output_size\n",
        "\n",
        "    #self.i2h = nn.Linear(input_size, output_size)\n",
        "    self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "    self.activation = nn.Tanh()\n",
        "    self.linear2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, target_seq, hidden):\n",
        "    batch_size, seq_length = target_seq.size()\n",
        "    outputs = torch.zeros(batch_size, seq_length, self.output_size).to(device)\n",
        "\n",
        "    for char_idx in range(seq_length):\n",
        "      if char_idx == 0:\n",
        "        #이전 input\n",
        "        previous_y = torch.zeros(batch_size, self.input_size).to(device)\n",
        "      else:\n",
        "        y_prev = target_seq[:, char_idx - 1]\n",
        "        # y_minus_1 = nn.functional.one_hot(y_prev, num_classes = self.liner1.in_features).float()\n",
        "        previous_y = nn.functional.one_hot(y_prev, self.input_size).float().to(device)\n",
        "\n",
        "      hidden = self.activation(self.linear1(previous_y) + hidden)\n",
        "      output = self.linear2(hidden)\n",
        "      outputs[:, char_idx, :] = output\n",
        "\n",
        "    return outputs\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, encoder, decoder):\n",
        "    super(Seq2Seq, self).__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def forward(self, input_seq, target_seq):\n",
        "    encoder_hidden = self.encoder(input_seq)\n",
        "    decoder_output = self.decoder(target_seq, encoder_hidden)\n",
        "\n",
        "    return decoder_output\n",
        "\n",
        "def train_model(model, detaloader, criterion, optimizer, num_epochs, device):\n",
        "  model.to(device)\n",
        "\n",
        "  for epoch in range(1, num_epochs + 1):\n",
        "   #train모드로 변경\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for inputs, targets in detaloader:\n",
        "      # input.shape - batch_size, seq_length\n",
        "      inputs,targets = inputs.to(device), targets.to(device)\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      outputs = model(inputs, targets)\n",
        "      outputs = outputs.view(-1, outputs.size(-1)) #batch_size + seq_length, output_size\n",
        "      targets = targets.view(-1)\n",
        "\n",
        "      loss = criterion(outputs, targets)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "      avg_loss = epoch_loss / len(dataloader)\n",
        "    print(f\"Epoch {epoch}, loss {avg_loss}\")\n",
        "\n",
        "def evaluate_model(model, dataloader, device):\n",
        "  model.eval()\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, targets in dataloader:\n",
        "      inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "      outputs = model(inputs, targets) #output : model을 통과 후 계산된 값, batch_size, seq_length, vocab_size\n",
        "\n",
        "      predicted = torch.argmax(outputs, dim = 2)\n",
        "      correct += (predicted == targets).sum().item()\n",
        "      total += targets.size(0) * targets.size(1) #targets.size[0] : batch_size\n",
        "\n",
        "  acc = correct / total\n",
        "  return acc\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "      seq_length = 10\n",
        "      num_samples = 1000\n",
        "      vocab_size = 50  # Including a padding index if needed\n",
        "      hidden_size = 64\n",
        "      batch_size = 32\n",
        "      num_epochs = 20\n",
        "      learning_rate = 0.001\n",
        "\n",
        "      #Device configuration\n",
        "      device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "      #print(f'Using device :{device}')\n",
        "\n",
        "      dataset = generate_dataset(seq_length, num_samples, vocab_size)\n",
        "\n",
        "      # for x, y in dataset:\n",
        "      #   print(x[0], y[0])\n",
        "      #   break\n",
        "      # #input 시퀀스가 있다면 input과 같은 output을 내뱉는 시퀀스 생성\n",
        "      dataloader = DataLoader(dataset, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "      encoder = Encoder(input_size=vocab_size, hidden_size=hidden_size)\n",
        "      decoder = Decoder(input_size=vocab_size, hidden_size=hidden_size, output_size=vocab_size)\n",
        "\n",
        "      model = Seq2Seq(encoder, decoder).to(device)\n",
        "\n",
        "      criterion = nn.CrossEntropyLoss()\n",
        "      optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "      train_model(model, dataloader, criterion, optimizer, num_epochs, device)\n",
        "\n",
        "      acc = evaluate_model(model, dataloader, device)\n",
        "      print(f\"Training Accuracy : {acc * 100:.2f}%\\n\")\n",
        "\n",
        "      with torch.no_grad():\n",
        "        test_input, test_target = dataset[0]\n",
        "        test_input = test_input.unsqueeze(0).to(device)\n",
        "        test_target = test_target.unsqueeze(0).to(device)\n",
        "\n",
        "        output = model(test_input, test_target)\n",
        "\n",
        "        predicted = torch.argmax(output, dim = 2)\n",
        "        print(\"Sample Input Sequence:   \", test_input.squeeze().tolist())\n",
        "        print(\"Sample Target Sequence:  \", test_target.squeeze().tolist())\n",
        "        print(\"Predicted Sequence       :  \", predicted.squeeze().tolist())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "nEgCuJSqkT4D",
        "outputId": "30910c9a-8862-4dc1-a1e6-bc515ed67b69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Encoder.__init__() missing 1 required positional argument: 'output_size'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-391f85087e17>\u001b[0m in \u001b[0;36m<cell line: 125>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    144\u001b[0m       \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m       \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m       \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Encoder.__init__() missing 1 required positional argument: 'output_size'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " t = torch.randn(10,3,5)\n",
        "print(t.view(-1, 10, 5).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "we5rPib6hjnA",
        "outputId": "6b49df13-1b19-4aa3-9fc3-0b11ffda01a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 10, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O2Q4_Pvy0aYF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
